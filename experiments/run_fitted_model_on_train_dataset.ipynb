{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the directory containing your script to sys.path\n",
    "sys.path.insert(0, '/home/bethge/bkr046/cem')\n",
    "\n",
    "#####\n",
    "\n",
    "import argparse\n",
    "import copy\n",
    "import joblib\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from cem.data.synthetic_loaders import (\n",
    "    get_synthetic_data_loader, get_synthetic_num_features\n",
    ")\n",
    "import cem.data.celeba_loader as celeba_data_module\n",
    "import cem.data.chexpert_loader as chexpert_data_module\n",
    "import cem.data.CUB200.cub_loader as cub_data_module\n",
    "import cem.data.derm_loader as derm_data_module\n",
    "import cem.data.mnist_add as mnist_data_module\n",
    "import cem.interventions.utils as intervention_utils\n",
    "import cem.train.training as training\n",
    "import cem.train.utils as utils\n",
    "\n",
    "from experiment_utils import (\n",
    "    evaluate_expressions, determine_rerun,\n",
    "    generate_hyperatemer_configs, filter_results,\n",
    "    print_table, get_mnist_extractor_arch\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# config\n",
    "\n",
    "from run_experiments import _build_arg_parser\n",
    "\n",
    "parser = _build_arg_parser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.config = 'configs/cub_config.yaml'\n",
    "\n",
    "if args.project_name:\n",
    "    # Lazy import to avoid importing unless necessary\n",
    "    pass #import wandb\n",
    "if args.debug:\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "else:\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "\n",
    "if args.config:\n",
    "    with open(args.config, \"r\") as f:\n",
    "        loaded_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "else:\n",
    "    loaded_config = {}\n",
    "if \"shared_params\" not in loaded_config:\n",
    "    loaded_config[\"shared_params\"] = {}\n",
    "if \"runs\" not in loaded_config:\n",
    "    loaded_config[\"runs\"] = []\n",
    "\n",
    "if args.dataset is not None:\n",
    "    loaded_config[\"dataset\"] = args.dataset\n",
    "if loaded_config.get(\"dataset\", None) is None:\n",
    "    raise ValueError(\n",
    "        \"A dataset must be provided either as part of the \"\n",
    "        \"configuration file or as a command line argument.\"\n",
    "    )\n",
    "if loaded_config[\"dataset\"] == \"cub\":\n",
    "    data_module = cub_data_module\n",
    "    args.project_name = args.project_name.format(ds_name=\"cub\")\n",
    "elif loaded_config[\"dataset\"] == \"derm\":\n",
    "    data_module = derm_data_module\n",
    "    args.project_name = args.project_name.format(ds_name=\"derma\")\n",
    "elif loaded_config[\"dataset\"] == \"celeba\":\n",
    "    data_module = celeba_data_module\n",
    "    args.project_name = args.project_name.format(ds_name=\"celeba\")\n",
    "elif loaded_config[\"dataset\"] == \"chexpert\":\n",
    "    data_module = chexpert_data_module\n",
    "    args.project_name = args.project_name.format(ds_name=\"chexpert\")\n",
    "elif loaded_config[\"dataset\"] in [\"xor\", \"vector\", \"dot\", \"trig\"]:\n",
    "    data_module = get_synthetic_data_loader(loaded_config[\"dataset\"])\n",
    "    args.project_name = args.project_name.format(\n",
    "        ds_name=loaded_config[\"dataset\"]\n",
    "    )\n",
    "    input_features = get_synthetic_num_features(loaded_config[\"dataset\"])\n",
    "    def synth_c_extractor_arch(\n",
    "        output_dim,\n",
    "        pretrained=False,\n",
    "    ):\n",
    "        if output_dim is None:\n",
    "            output_dim = 128\n",
    "        return torch.nn.Sequential(*[\n",
    "            torch.nn.Linear(input_features, 128),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(128, output_dim),\n",
    "        ])\n",
    "    loaded_config[\"c_extractor_arch\"] = synth_c_extractor_arch\n",
    "elif loaded_config[\"dataset\"] == \"mnist_add\":\n",
    "    data_module = mnist_data_module\n",
    "    args.project_name = args.project_name.format(ds_name=args.dataset)\n",
    "    utils.extend_with_global_params(\n",
    "        loaded_config,\n",
    "        args.param or []\n",
    "    )\n",
    "    num_operands = loaded_config.get('num_operands', 32)\n",
    "    loaded_config[\"c_extractor_arch\"] = get_mnist_extractor_arch(\n",
    "        input_shape=(\n",
    "            loaded_config.get('batch_size', 512),\n",
    "            num_operands,\n",
    "            28,\n",
    "            28,\n",
    "        ),\n",
    "        num_operands=num_operands,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported dataset {loaded_config['dataset']}!\")\n",
    "\n",
    "if args.output_dir is not None:\n",
    "    loaded_config['results_dir'] = args.output_dir\n",
    "if args.debug:\n",
    "    print(json.dumps(loaded_config, sort_keys=True, indent=4))\n",
    "logging.info(f\"Results will be dumped in {loaded_config['results_dir']}\")\n",
    "logging.debug(\n",
    "    f\"And the dataset's root directory is {loaded_config.get('root_dir')}\"\n",
    ")\n",
    "Path(loaded_config['results_dir']).mkdir(parents=True, exist_ok=True)\n",
    "# Write down the actual command executed\n",
    "# And the configuration file\n",
    "now = datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "loaded_config[\"time_last_called\"] = now.strftime(\"%Y/%m/%d at %H:%M:%S\")\n",
    "with open(\n",
    "    os.path.join(loaded_config['results_dir'], f\"command_{dt_string}.txt\"),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    command_args = [\n",
    "        arg if \" \" not in arg else f'\"{arg}\"' for arg in sys.argv\n",
    "    ]\n",
    "    f.write(\"python \" + \" \".join(command_args))\n",
    "\n",
    "# Also save the current experiment configuration\n",
    "with open(\n",
    "    os.path.join(\n",
    "        loaded_config['results_dir'],\n",
    "        f\"experiment_{dt_string}_config.yaml\")\n",
    "    ,\n",
    "    \"w\"\n",
    ") as f:\n",
    "    yaml.dump(loaded_config, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "rerun=args.rerun\n",
    "result_dir=(\n",
    "    args.output_dir if args.output_dir\n",
    "    else loaded_config['results_dir']\n",
    ")\n",
    "project_name=args.project_name\n",
    "num_workers=args.num_workers\n",
    "global_params=args.param\n",
    "accelerator=(\n",
    "    \"gpu\" if (not args.force_cpu) and (torch.cuda.is_available())\n",
    "    else \"cpu\"\n",
    ")\n",
    "experiment_config=loaded_config\n",
    "activation_freq=args.activation_freq\n",
    "single_frequency_epochs=args.single_frequency_epochs\n",
    "\n",
    "\n",
    "devices = 'auto'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "seed_everything(42)\n",
    "# parameters for data, model, and training\n",
    "experiment_config = copy.deepcopy(experiment_config)\n",
    "if 'shared_params' not in experiment_config:\n",
    "    experiment_config['shared_params'] = {}\n",
    "# Move all global things into the shared params\n",
    "for key, vals in experiment_config.items():\n",
    "    if key not in ['runs', 'shared_params']:\n",
    "        experiment_config['shared_params'][key] = vals\n",
    "experiment_config['shared_params']['num_workers'] = num_workers\n",
    "\n",
    "utils.extend_with_global_params(\n",
    "    experiment_config['shared_params'], global_params or []\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_dl, val_dl, test_dl, imbalance, (n_concepts, n_tasks, concept_map) = \\\n",
    "    data_module.generate_data(\n",
    "        config=experiment_config['shared_params'],\n",
    "        seed=42,\n",
    "        output_dataset_vars=True,\n",
    "        root_dir=experiment_config['shared_params'].get('root_dir', None),\n",
    "    )\n",
    "\n",
    "# For now, we assume that all concepts have the same\n",
    "# aquisition cost\n",
    "acquisition_costs = None\n",
    "if concept_map is not None:\n",
    "    intervened_groups = list(\n",
    "        range(\n",
    "            0,\n",
    "            len(concept_map) + 1,\n",
    "            experiment_config['shared_params'].get('intervention_freq', 1),\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    intervened_groups = list(\n",
    "        range(\n",
    "            0,\n",
    "            n_concepts + 1,\n",
    "            experiment_config['shared_params'].get('intervention_freq', 1),\n",
    "        )\n",
    "    )\n",
    "experiment_config[\"shared_params\"][\"n_concepts\"] = \\\n",
    "    experiment_config[\"shared_params\"].get(\n",
    "        \"n_concepts\",\n",
    "        n_concepts,\n",
    "    )\n",
    "experiment_config[\"shared_params\"][\"n_tasks\"] = \\\n",
    "    experiment_config[\"shared_params\"].get(\n",
    "        \"n_tasks\",\n",
    "        n_tasks,\n",
    "    )\n",
    "experiment_config[\"shared_params\"][\"concept_map\"] = \\\n",
    "    experiment_config[\"shared_params\"].get(\n",
    "        \"concept_map\",\n",
    "        concept_map,\n",
    "    )\n",
    "\n",
    "sample = next(iter(train_dl))\n",
    "real_sample = []\n",
    "for x in sample:\n",
    "    if isinstance(x, list):\n",
    "        real_sample += x\n",
    "    else:\n",
    "        real_sample.append(x)\n",
    "sample = real_sample\n",
    "logging.info(\n",
    "    f\"Training sample shape is: {sample[0].shape} with \"\n",
    "    f\"type {sample[0].type()}\"\n",
    ")\n",
    "logging.info(\n",
    "    f\"Training label shape is: {sample[1].shape} with \"\n",
    "    f\"type {sample[1].type()}\"\n",
    ")\n",
    "logging.info(\n",
    "    f\"\\tNumber of output classes: {n_tasks}\"\n",
    ")\n",
    "logging.info(\n",
    "    f\"Training concept shape is: {sample[2].shape} with \"\n",
    "    f\"type {sample[2].type()}\"\n",
    ")\n",
    "logging.info(\n",
    "    f\"\\tNumber of training concepts: {n_concepts}\"\n",
    ")\n",
    "\n",
    "task_class_weights = None\n",
    "\n",
    "if experiment_config['shared_params'].get('use_task_class_weights', False):\n",
    "    logging.info(\n",
    "        f\"Computing task class weights in the training dataset with \"\n",
    "        f\"size {len(train_dl)}...\"\n",
    "    )\n",
    "    attribute_count = np.zeros((max(n_tasks, 2),))\n",
    "    samples_seen = 0\n",
    "    for i, data in enumerate(train_dl):\n",
    "        if len(data) == 2:\n",
    "            (_, (y, _)) = data\n",
    "        else:\n",
    "            (_, y, _) = data\n",
    "        if n_tasks > 1:\n",
    "            y = torch.nn.functional.one_hot(\n",
    "                y,\n",
    "                num_classes=n_tasks,\n",
    "            ).cpu().detach().numpy()\n",
    "        else:\n",
    "            y = torch.cat(\n",
    "                [torch.unsqueeze(1 - y, dim=-1), torch.unsqueeze(y, dim=-1)],\n",
    "                dim=-1,\n",
    "            ).cpu().detach().numpy()\n",
    "        attribute_count += np.sum(y, axis=0)\n",
    "        samples_seen += y.shape[0]\n",
    "    print(\"Class distribution is:\", attribute_count / samples_seen)\n",
    "    if n_tasks > 1:\n",
    "        task_class_weights = samples_seen / attribute_count - 1\n",
    "    else:\n",
    "        task_class_weights = np.array(\n",
    "            [attribute_count[0]/attribute_count[1]]\n",
    "        )\n",
    "\n",
    "\n",
    "# Set log level in env variable as this will be necessary for\n",
    "# subprocessing\n",
    "os.environ['LOGLEVEL'] = os.environ.get(\n",
    "    'LOGLEVEL',\n",
    "    logging.getLevelName(logging.getLogger().getEffectiveLevel()),\n",
    ")\n",
    "loglevel = os.environ['LOGLEVEL']\n",
    "logging.info(f'Setting log level to: \"{loglevel}\"')\n",
    "\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "results = {}\n",
    "for split in range(\n",
    "    experiment_config['shared_params'].get(\"start_split\", 0),\n",
    "    experiment_config['shared_params'][\"trials\"],\n",
    "):\n",
    "    results[f'{split}'] = {}\n",
    "    now = datetime.now()\n",
    "    print(\n",
    "        f\"[TRIAL \"\n",
    "        f\"{split + 1}/{experiment_config['shared_params']['trials']} \"\n",
    "        f\"BEGINS AT {now.strftime('%d/%m/%Y at %H:%M:%S')}\"\n",
    "    )\n",
    "    # And then over all runs in a given trial\n",
    "    for current_config in experiment_config['runs']:\n",
    "        # Construct the config for this particular trial\n",
    "        trial_config = copy.deepcopy(experiment_config.get('shared_params', {}))\n",
    "\n",
    "        trial_config.update(current_config)\n",
    "        trial_config[\"concept_map\"] = concept_map\n",
    "        # Now time to iterate 5\n",
    "        # over all hyperparameters that were given as part\n",
    "        for run_config in generate_hyperatemer_configs(trial_config):\n",
    "            now = datetime.now()\n",
    "            run_config = copy.deepcopy(run_config)\n",
    "            evaluate_expressions(run_config)\n",
    "            run_config[\"extra_name\"] = run_config.get(\"extra_name\", \"\").format(\n",
    "                **run_config\n",
    "            )\n",
    "            old_results = None\n",
    "            full_run_name = (\n",
    "                f\"{run_config['architecture']}{run_config.get('extra_name', '')}\"\n",
    "            )\n",
    "            current_results_path = os.path.join(\n",
    "                result_dir,\n",
    "                f'{full_run_name}_split_{split}_results.joblib'\n",
    "            )\n",
    "            current_rerun = determine_rerun(\n",
    "                config=run_config,\n",
    "                rerun=rerun,\n",
    "                split=split,\n",
    "                full_run_name=full_run_name,\n",
    "            )\n",
    "            if current_rerun:\n",
    "                logging.warning(\n",
    "                    f\"We will rerun model {full_run_name}_split_{split} \"\n",
    "                    f\"as requested by the config\"\n",
    "                )\n",
    "            if (not current_rerun) and os.path.exists(current_results_path):\n",
    "                with open(current_results_path, 'rb') as f:\n",
    "                    old_results = joblib.load(f)\n",
    "\n",
    "            if run_config[\"architecture\"] in [\n",
    "                \"IndependentConceptBottleneckModel\",\n",
    "                \"SequentialConceptBottleneckModel\",\n",
    "            ]:\n",
    "                # Special case for now for sequential and independent CBMs\n",
    "                config = copy.deepcopy(run_config)\n",
    "                config[\"architecture\"] = \"ConceptBottleneckModel\"\n",
    "                config[\"sigmoidal_prob\"] = True\n",
    "                full_run_name = (\n",
    "                    f\"{config['architecture']}{config.get('extra_name', '')}\"\n",
    "                )\n",
    "                seq_old_results = None\n",
    "                seq_current_results_path = os.path.join(\n",
    "                    result_dir,\n",
    "                    f'Sequential{full_run_name}_split_{split}_results.joblib'\n",
    "                )\n",
    "                if os.path.exists(seq_current_results_path):\n",
    "                    with open(seq_current_results_path, 'rb') as f:\n",
    "                        seq_old_results = joblib.load(f)\n",
    "\n",
    "                ind_old_results = None\n",
    "                ind_current_results_path = os.path.join(\n",
    "                    result_dir,\n",
    "                    f'Sequential{full_run_name}_split_{split}_results.joblib'\n",
    "                )\n",
    "                if os.path.exists(ind_current_results_path):\n",
    "                    with open(ind_current_results_path, 'rb') as f:\n",
    "                        ind_old_results = joblib.load(f)\n",
    "                ind_model, ind_test_results, seq_model, seq_test_results = \\\n",
    "                    training.train_independent_and_sequential_model(\n",
    "                        task_class_weights=task_class_weights,\n",
    "                        n_concepts=n_concepts,\n",
    "                        n_tasks=n_tasks,\n",
    "                        config=config,\n",
    "                        train_dl=train_dl,\n",
    "                        val_dl=val_dl,\n",
    "                        test_dl=test_dl,\n",
    "                        split=split,\n",
    "                        result_dir=result_dir,\n",
    "                        rerun=current_rerun,\n",
    "                        project_name=project_name,\n",
    "                        seed=(42 + split),\n",
    "                        imbalance=imbalance,\n",
    "                        ind_old_results=ind_old_results,\n",
    "                        seq_old_results=seq_old_results,\n",
    "                        single_frequency_epochs=single_frequency_epochs,\n",
    "                        activation_freq=activation_freq,\n",
    "                    )\n",
    "\n",
    "                config[\"architecture\"] = \"IndependentConceptBottleneckModel\"\n",
    "                training.update_statistics(\n",
    "                    results[f'{split}'],\n",
    "                    config,\n",
    "                    ind_model,\n",
    "                    ind_test_results,\n",
    "                )\n",
    "                full_run_name = (\n",
    "                    f\"{config['architecture']}{config.get('extra_name', '')}\"\n",
    "                )\n",
    "                results[f'{split}'].update(\n",
    "                    intervention_utils.test_interventions(\n",
    "                        task_class_weights=task_class_weights,\n",
    "                        full_run_name=full_run_name,\n",
    "                        train_dl=train_dl,\n",
    "                        val_dl=val_dl,\n",
    "                        test_dl=test_dl,\n",
    "                        imbalance=imbalance,\n",
    "                        config=config,\n",
    "                        n_tasks=n_tasks,\n",
    "                        n_concepts=n_concepts,\n",
    "                        acquisition_costs=acquisition_costs,\n",
    "                        result_dir=result_dir,\n",
    "                        concept_map=concept_map,\n",
    "                        intervened_groups=intervened_groups,\n",
    "                        accelerator=accelerator,\n",
    "                        devices=devices,\n",
    "                        split=split,\n",
    "                        rerun=current_rerun,\n",
    "                        old_results=ind_old_results,\n",
    "                        independent=True,\n",
    "                        competence_levels=config.get(\n",
    "                        'competence_levels',\n",
    "                        [1],\n",
    "                    ),\n",
    "                    )\n",
    "                )\n",
    "                logging.debug(\n",
    "                    f\"\\tResults for {full_run_name} in split {split}:\"\n",
    "                )\n",
    "                for key, val in filter_results(\n",
    "                    results[f'{split}'],\n",
    "                    full_run_name,\n",
    "                    cut=True,\n",
    "                ).items():\n",
    "                    logging.debug(f\"\\t\\t{key} -> {val}\")\n",
    "                with open(ind_current_results_path, 'wb') as f:\n",
    "                    joblib.dump(\n",
    "                        filter_results(results[f'{split}'], full_run_name),\n",
    "                        f,\n",
    "                    )\n",
    "\n",
    "                config[\"architecture\"] = \"SequentialConceptBottleneckModel\"\n",
    "                training.update_statistics(\n",
    "                    results[f'{split}'],\n",
    "                    config,\n",
    "                    seq_model,\n",
    "                    seq_test_results,\n",
    "                )\n",
    "                full_run_name = (\n",
    "                    f\"{config['architecture']}{config.get('extra_name', '')}\"\n",
    "                )\n",
    "                results[f'{split}'].update(\n",
    "                    intervention_utils.test_interventions(\n",
    "                        task_class_weights=task_class_weights,\n",
    "                        full_run_name=full_run_name,\n",
    "                        train_dl=train_dl,\n",
    "                        val_dl=val_dl,\n",
    "                        test_dl=test_dl,\n",
    "                        imbalance=imbalance,\n",
    "                        config=config,\n",
    "                        n_tasks=n_tasks,\n",
    "                        n_concepts=n_concepts,\n",
    "                        acquisition_costs=acquisition_costs,\n",
    "                        result_dir=result_dir,\n",
    "                        concept_map=concept_map,\n",
    "                        intervened_groups=intervened_groups,\n",
    "                        accelerator=accelerator,\n",
    "                        devices=devices,\n",
    "                        split=split,\n",
    "                        rerun=current_rerun,\n",
    "                        old_results=seq_old_results,\n",
    "                        sequential=True,\n",
    "                        competence_levels=config.get('competence_levels', [1]),\n",
    "                    )\n",
    "                )\n",
    "                logging.debug(\n",
    "                    f\"\\tResults for {full_run_name} in split {split}:\"\n",
    "                )\n",
    "                for key, val in filter_results(\n",
    "                    results[f'{split}'],\n",
    "                    full_run_name,\n",
    "                    cut=True,\n",
    "                ).items():\n",
    "                    logging.debug(f\"\\t\\t{key} -> {val}\")\n",
    "                with open(seq_current_results_path, 'wb') as f:\n",
    "                    joblib.dump(\n",
    "                        filter_results(results[f'{split}'], full_run_name),\n",
    "                        f,\n",
    "                    )\n",
    "                if experiment_config['shared_params'].get(\"start_split\", 0) == 0:\n",
    "                    attempt = 0\n",
    "                    # We will try and dump things a few times in case there\n",
    "                    # are other threads/processes currently modifying or\n",
    "                    # writing this same file\n",
    "                    while attempt < 5:\n",
    "                        try:\n",
    "                            with open(\n",
    "                                os.path.join(result_dir, f'results.joblib'),\n",
    "                                'wb',\n",
    "                            ) as f:\n",
    "                                joblib.dump(results, f)\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(\n",
    "                                \"FAILED TO SERIALIZE RESULTS TO\",\n",
    "                                os.path.join(result_dir, f'results.joblib')\n",
    "                            )\n",
    "                            attempt += 1\n",
    "                    if attempt == 5:\n",
    "                        raise ValueError(\n",
    "                            \"Could not serialize \" +\n",
    "                            os.path.join(result_dir, f'results.joblib') +\n",
    "                            \" to disk\"\n",
    "                        )\n",
    "            else:\n",
    "                config = run_config\n",
    "                model, model_results = \\\n",
    "                    training.train_model(\n",
    "                        task_class_weights=task_class_weights,\n",
    "                        accelerator=accelerator,\n",
    "                        devices=devices,\n",
    "                        n_concepts=n_concepts,\n",
    "                        n_tasks=n_tasks,\n",
    "                        config=run_config,\n",
    "                        train_dl=train_dl,\n",
    "                        val_dl=val_dl,\n",
    "                        test_dl=test_dl,\n",
    "                        split=split,\n",
    "                        result_dir=result_dir,\n",
    "                        rerun=current_rerun,\n",
    "                        project_name=project_name,\n",
    "                        seed=(42 + split),\n",
    "                        imbalance=imbalance,\n",
    "                        old_results=old_results,\n",
    "                        gradient_clip_val=run_config.get(\n",
    "                            'gradient_clip_val',\n",
    "                            0,\n",
    "                        ),\n",
    "                        single_frequency_epochs=single_frequency_epochs,\n",
    "                        activation_freq=activation_freq,\n",
    "                    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "torch.save(model, '/mnt/qb/work/bethge/bkr046/CEM/models/CUB_CEM.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# # save CEM params to load it later\n",
    "# import pickle\n",
    "\n",
    "# cem_params = {\n",
    "#     'task_class_weights': task_class_weights,\n",
    "#     'accelerator': accelerator,\n",
    "#     'devices': devices,\n",
    "#     'n_concepts': n_concepts,\n",
    "#     'n_tasks': n_tasks,\n",
    "#     'config': run_config,\n",
    "#     'train_dl': train_dl,\n",
    "#     'val_dl': val_dl,\n",
    "#     'test_dl': test_dl,\n",
    "#     'split': split,\n",
    "#     'result_dir': result_dir,\n",
    "#     'rerun': current_rerun,\n",
    "#     'project_name': project_name,\n",
    "#     'seed': (42 + split),\n",
    "#     'imbalance': imbalance,\n",
    "#     'old_results': old_results,\n",
    "#     'gradient_clip_val': run_config.get('gradient_clip_val', 0),\n",
    "#     'single_frequency_epochs': single_frequency_epochs,\n",
    "#     'activation_freq': activation_freq,\n",
    "# }\n",
    "\n",
    "# with open(\"../examples/CEM_CUB_params.pickle\", 'wb') as f:\n",
    "#     pickle.dump(cem_params, f)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "config"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "import copy\n",
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import cem.metrics.niching as niching\n",
    "import cem.metrics.oracle as oracle\n",
    "import cem.train.utils as utils\n",
    "\n",
    "from cem.metrics.cas import concept_alignment_score\n",
    "from cem.models.construction import (\n",
    "    construct_model,\n",
    "    construct_sequential_models,\n",
    "    load_trained_model,\n",
    ")\n",
    "\n",
    "def get_ind_seq_models(\n",
    "n_concepts,\n",
    "n_tasks,\n",
    "config,\n",
    "train_dl,\n",
    "val_dl,\n",
    "result_dir=None,\n",
    "test_dl=None,\n",
    "split=None,\n",
    "imbalance=None,\n",
    "task_class_weights=None,\n",
    "rerun=False,\n",
    "logger=False,\n",
    "project_name='',\n",
    "seed=None,\n",
    "save_model=True,\n",
    "activation_freq=0,\n",
    "single_frequency_epochs=0,\n",
    "accelerator=\"auto\",\n",
    "devices=\"auto\",\n",
    "ind_old_results=None,\n",
    "seq_old_results=None,\n",
    "enable_checkpointing=False,\n",
    "):\n",
    "    if seed is not None:\n",
    "        seed_everything(seed)\n",
    "    num_epochs = 0\n",
    "    training_time = 0\n",
    "\n",
    "    extr_name = config['c_extractor_arch']\n",
    "    if not isinstance(extr_name, str):\n",
    "        extr_name = \"lambda\"\n",
    "    if split is not None:\n",
    "        ind_full_run_name = (\n",
    "            f\"IndependentConceptBottleneckModel\"\n",
    "            f\"{config.get('extra_name', '')}_{extr_name}_fold_{split + 1}\"\n",
    "        )\n",
    "        seq_full_run_name = (\n",
    "            f\"SequentialConceptBottleneckModel\"\n",
    "            f\"{config.get('extra_name', '')}_{extr_name}_fold_{split + 1}\"\n",
    "        )\n",
    "    else:\n",
    "        ind_full_run_name = (\n",
    "            f\"IndependentConceptBottleneckModel\"\n",
    "            f\"{config.get('extra_name', '')}_{extr_name}\"\n",
    "        )\n",
    "        seq_full_run_name = (\n",
    "            f\"SequentialConceptBottleneckModel\"\n",
    "            f\"{config.get('extra_name', '')}_{extr_name}\"\n",
    "        )\n",
    "    print(f\"[Training {ind_full_run_name} and {seq_full_run_name}]\")\n",
    "    print(\"config:\")\n",
    "    for key, val in config.items():\n",
    "        print(f\"\\t{key} -> {val}\")\n",
    "\n",
    "    # Create the two models we will manipulate\n",
    "    # Else, let's construct the two models we will need for this\n",
    "    _, ind_c2y_model = construct_sequential_models(\n",
    "        n_concepts,\n",
    "        n_tasks,\n",
    "        config,\n",
    "        imbalance=imbalance,\n",
    "        task_class_weights=task_class_weights,\n",
    "    )\n",
    "\n",
    "    _, seq_c2y_model = construct_sequential_models(\n",
    "        n_concepts,\n",
    "        n_tasks,\n",
    "        config,\n",
    "        imbalance=imbalance,\n",
    "        task_class_weights=task_class_weights,\n",
    "    )\n",
    "\n",
    "    # As well as the wrapper CBM model we will use for serialization\n",
    "    # and testing\n",
    "    # We will be a bit cheeky and use the model with the task loss\n",
    "    # weight set to 0 for training with the same dataset\n",
    "    model_config = copy.deepcopy(config)\n",
    "    model_config['concept_loss_weight'] = 1\n",
    "    model_config['task_loss_weight'] = 0\n",
    "    model = construct_model(\n",
    "        n_concepts,\n",
    "        n_tasks,\n",
    "        config=model_config,\n",
    "        imbalance=imbalance,\n",
    "        task_class_weights=task_class_weights,\n",
    "    )\n",
    "    print(\n",
    "        \"[Number of parameters in model\",\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "        \"]\",\n",
    "    )\n",
    "    print(\n",
    "        \"[Number of non-trainable parameters in model\",\n",
    "        sum(p.numel() for p in model.parameters() if not p.requires_grad),\n",
    "        \"]\",\n",
    "    )\n",
    "    seq_model_saved_path = os.path.join(\n",
    "        result_dir,\n",
    "        f'{seq_full_run_name}.pt'\n",
    "    )\n",
    "    ind_model_saved_path = os.path.join(\n",
    "        result_dir,\n",
    "        f'{ind_full_run_name}.pt'\n",
    "    )\n",
    "    chpt_exists = (\n",
    "        os.path.exists(ind_model_saved_path) and\n",
    "        os.path.exists(seq_model_saved_path)\n",
    "    )\n",
    "    # Construct the datasets we will need for training if the model\n",
    "    # has not been found\n",
    "    if rerun or (not chpt_exists):\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        c_train = []\n",
    "        for elems in train_dl:\n",
    "            if len(elems) == 2:\n",
    "                (x, (y, c)) = elems\n",
    "            else:\n",
    "                (x, y, c) = elems\n",
    "            x_train.append(x.cpu().detach())\n",
    "            y_train.append(y.cpu().detach())\n",
    "            c_train.append(c.cpu().detach())\n",
    "        x_train = np.concatenate(x_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        c_train = np.concatenate(c_train, axis=0)\n",
    "\n",
    "        if test_dl:\n",
    "            x_test = []\n",
    "            y_test = []\n",
    "            c_test = []\n",
    "            for elems in test_dl:\n",
    "                if len(elems) == 2:\n",
    "                    (x, (y, c)) = elems\n",
    "                else:\n",
    "                    (x, y, c) = elems\n",
    "                x_test.append(x.cpu().detach())\n",
    "                y_test.append(y.cpu().detach())\n",
    "                c_test.append(c.cpu().detach())\n",
    "            x_test = np.concatenate(x_test, axis=0)\n",
    "            y_test = np.concatenate(y_test, axis=0)\n",
    "            c_test = np.concatenate(c_test, axis=0)\n",
    "        if val_dl is not None:\n",
    "            x_val = []\n",
    "            y_val = []\n",
    "            c_val = []\n",
    "            for elems in val_dl:\n",
    "                if len(elems) == 2:\n",
    "                    (x, (y, c)) = elems\n",
    "                else:\n",
    "                    (x, y, c) = elems\n",
    "                x_val.append(x.cpu().detach())\n",
    "                y_val.append(y.cpu().detach())\n",
    "                c_val.append(c.cpu().detach())\n",
    "            x_val = np.concatenate(x_val, axis=0)\n",
    "            y_val = np.concatenate(y_val, axis=0)\n",
    "            c_val = np.concatenate(c_val, axis=0)\n",
    "        else:\n",
    "            c2y_val_dl = None\n",
    "\n",
    "\n",
    "    if (project_name) and result_dir and (not chpt_exists):\n",
    "        # Lazy import to avoid importing unless necessary\n",
    "        import wandb\n",
    "        enter_obj = wandb.init(\n",
    "            project=project_name,\n",
    "            name=ind_full_run_name,\n",
    "            config=config,\n",
    "            reinit=True\n",
    "        )\n",
    "    else:\n",
    "        enter_obj = utils.EmptyEnter()\n",
    "    with enter_obj as run:\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=accelerator,\n",
    "            devices=devices,\n",
    "            # We will distribute half epochs in one model and half on the other\n",
    "            max_epochs=config['max_epochs'],\n",
    "            check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\", 5),\n",
    "            callbacks=[\n",
    "                EarlyStopping(\n",
    "                    monitor=config[\"early_stopping_monitor\"],\n",
    "                    min_delta=config.get(\"early_stopping_delta\", 0.00),\n",
    "                    patience=config['patience'],\n",
    "                    verbose=config.get(\"verbose\", False),\n",
    "                    mode=config[\"early_stopping_mode\"],\n",
    "                ),\n",
    "            ],\n",
    "            # Only use the wandb logger when it is a fresh run\n",
    "            logger=(\n",
    "                logger or\n",
    "                (WandbLogger(\n",
    "                    name=ind_full_run_name,\n",
    "                    project=project_name,\n",
    "                    save_dir=os.path.join(result_dir, \"logs\"),\n",
    "                ) if project_name and (rerun or (not chpt_exists)) else False)\n",
    "            ),\n",
    "        )\n",
    "        if activation_freq:\n",
    "            raise ValueError(\n",
    "                \"Activation drop has not yet been tested for \"\n",
    "                \"joint/sequential models!\"\n",
    "            )\n",
    "        else:\n",
    "            x2c_trainer = trainer\n",
    "        if (not rerun) and chpt_exists:\n",
    "            # Then we simply load the model and proceed\n",
    "            print(\"\\tFound cached model... loading it\")\n",
    "            ind_model = construct_model(\n",
    "                n_concepts=n_concepts,\n",
    "                n_tasks=n_tasks,\n",
    "                config=config,\n",
    "                imbalance=imbalance,\n",
    "                task_class_weights=task_class_weights,\n",
    "                x2c_model=model.x2c_model,\n",
    "                c2y_model=ind_c2y_model,\n",
    "            )\n",
    "            ind_model.load_state_dict(torch.load(ind_model_saved_path))\n",
    "            if os.path.exists(\n",
    "                ind_model_saved_path.replace(\".pt\", \"_training_times.npy\")\n",
    "            ):\n",
    "                [ind_training_time, ind_num_epochs] = np.load(\n",
    "                    ind_model_saved_path.replace(\".pt\", \"_training_times.npy\")\n",
    "                )\n",
    "            else:\n",
    "                ind_training_time, ind_num_epochs = 0, 0\n",
    "\n",
    "            seq_model = construct_model(\n",
    "                n_concepts=n_concepts,\n",
    "                n_tasks=n_tasks,\n",
    "                config=config,\n",
    "                imbalance=imbalance,\n",
    "                task_class_weights=task_class_weights,\n",
    "                x2c_model=model.x2c_model,\n",
    "                c2y_model=seq_c2y_model,\n",
    "            )\n",
    "            seq_model.load_state_dict(torch.load(seq_model_saved_path))\n",
    "            if os.path.exists(\n",
    "                seq_model_saved_path.replace(\".pt\", \"_training_times.npy\")\n",
    "            ):\n",
    "                [seq_training_time, seq_num_epochs] = np.load(\n",
    "                    seq_model_saved_path.replace(\".pt\", \"_training_times.npy\")\n",
    "                )\n",
    "            else:\n",
    "                seq_training_time, seq_num_epochs = 0, 0\n",
    "        else:\n",
    "            # First train the input to concept model\n",
    "            print(\"[Training input to concept model]\")\n",
    "            start_time = time.time()\n",
    "            x2c_trainer.fit(model, train_dl, val_dl)\n",
    "            training_time += time.time() - start_time\n",
    "            num_epochs += x2c_trainer.current_epoch\n",
    "            if val_dl is not None:\n",
    "                print(\n",
    "                    \"Validation results for x2c model:\",\n",
    "                    x2c_trainer.test(model, val_dl),\n",
    "                )\n",
    "\n",
    "            # Time to construct intermediate dataset for independent model!\n",
    "            print(\n",
    "                \"[Constructing dataset for independent concept to label model]\"\n",
    "            )\n",
    "            ind_c2y_train_dl = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(\n",
    "                    torch.from_numpy(\n",
    "                        c_train\n",
    "                    ),\n",
    "                    torch.from_numpy(y_train),\n",
    "                ),\n",
    "                shuffle=True,\n",
    "                batch_size=config['batch_size'],\n",
    "                num_workers=config.get('num_workers', 5),\n",
    "            )\n",
    "            if val_dl is not None:\n",
    "                ind_c2y_val_dl = torch.utils.data.DataLoader(\n",
    "                    torch.utils.data.TensorDataset(\n",
    "                        torch.from_numpy(\n",
    "                            c_val\n",
    "                        ),\n",
    "                        torch.from_numpy(y_val),\n",
    "                    ),\n",
    "                    batch_size=config['batch_size'],\n",
    "                    num_workers=config.get('num_workers', 5),\n",
    "                )\n",
    "            else:\n",
    "                ind_c2y_val_dl = None\n",
    "\n",
    "            print(\n",
    "                \"[Constructing dataset for sequential concept to label model]\"\n",
    "            )\n",
    "            train_batch_concepts = trainer.predict(\n",
    "                model,\n",
    "                torch.utils.data.DataLoader(\n",
    "                    torch.utils.data.TensorDataset(\n",
    "                        torch.from_numpy(x_train),\n",
    "                        torch.from_numpy(y_train),\n",
    "                        torch.from_numpy(c_train),\n",
    "                    ),\n",
    "                    batch_size=1,\n",
    "                    num_workers=config.get('num_workers', 5),\n",
    "                ),\n",
    "            )\n",
    "            train_complete_concepts = np.concatenate(\n",
    "                list(map(lambda x: x[1], train_batch_concepts)),\n",
    "                axis=0,\n",
    "            )\n",
    "            seq_c2y_train_dl = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(\n",
    "                    torch.from_numpy(\n",
    "                        train_complete_concepts\n",
    "                    ),\n",
    "                    torch.from_numpy(y_train),\n",
    "                ),\n",
    "                shuffle=True,\n",
    "                batch_size=config['batch_size'],\n",
    "                num_workers=config.get('num_workers', 5),\n",
    "            )\n",
    "\n",
    "            if val_dl is not None:\n",
    "                val_batch_concepts = trainer.predict(\n",
    "                    model,\n",
    "                    torch.utils.data.DataLoader(\n",
    "                        torch.utils.data.TensorDataset(\n",
    "                            torch.from_numpy(x_val),\n",
    "                            torch.from_numpy(y_val),\n",
    "                            torch.from_numpy(c_val),\n",
    "                        ),\n",
    "                        batch_size=1,\n",
    "                        num_workers=config.get('num_workers', 5),\n",
    "                    ),\n",
    "                )\n",
    "                val_complete_concepts = np.concatenate(\n",
    "                    list(map(lambda x: x[1], val_batch_concepts)),\n",
    "                    axis=0,\n",
    "                )\n",
    "                seq_c2y_val_dl = torch.utils.data.DataLoader(\n",
    "                    torch.utils.data.TensorDataset(\n",
    "                        torch.from_numpy(\n",
    "                            val_complete_concepts\n",
    "                        ),\n",
    "                        torch.from_numpy(y_val),\n",
    "                    ),\n",
    "                    batch_size=config['batch_size'],\n",
    "                    num_workers=config.get('num_workers', 5),\n",
    "                )\n",
    "            else:\n",
    "                seq_c2y_val_dl = None\n",
    "\n",
    "            # Train the independent concept to label model\n",
    "            print(\"[Training independent concept to label model]\")\n",
    "            ind_c2y_trainer = pl.Trainer(\n",
    "                accelerator=accelerator,\n",
    "                devices=devices,\n",
    "                # We will distribute half epochs in one model and half on the\n",
    "                # other\n",
    "                max_epochs=config.get('c2y_max_epochs', 50),\n",
    "                enable_checkpointing=enable_checkpointing,\n",
    "                check_val_every_n_epoch=config.get(\n",
    "                    \"check_val_every_n_epoch\",\n",
    "                    5,\n",
    "                ),\n",
    "                callbacks=[\n",
    "                    EarlyStopping(\n",
    "                        monitor=config[\"early_stopping_monitor\"],\n",
    "                        min_delta=config.get(\"early_stopping_delta\", 0.00),\n",
    "                        patience=config['patience'],\n",
    "                        verbose=config.get(\"verbose\", False),\n",
    "                        mode=config[\"early_stopping_mode\"],\n",
    "                    ),\n",
    "                ],\n",
    "                # Only use the wandb logger when it is a fresh run\n",
    "                logger=(\n",
    "                    logger or\n",
    "                    (\n",
    "                        WandbLogger(\n",
    "                            name=ind_full_run_name,\n",
    "                            project=project_name,\n",
    "                            save_dir=os.path.join(result_dir, \"logs\"),\n",
    "                        ) if project_name and (rerun or (not chpt_exists))\n",
    "                        else False\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "            start_time = time.time()\n",
    "            ind_c2y_trainer.fit(\n",
    "                ind_c2y_model,\n",
    "                ind_c2y_train_dl,\n",
    "                ind_c2y_val_dl,\n",
    "            )\n",
    "            ind_training_time = training_time + time.time() - start_time\n",
    "            ind_num_epochs = num_epochs + ind_c2y_trainer.current_epoch\n",
    "            if ind_c2y_val_dl is not None:\n",
    "                print(\n",
    "                    \"Independent validation results for c2y model:\",\n",
    "                    ind_c2y_trainer.test(ind_c2y_model, ind_c2y_val_dl),\n",
    "                )\n",
    "\n",
    "            # Train the sequential concept to label model\n",
    "            print(\"[Training sequential concept to label model]\")\n",
    "            seq_c2y_trainer = pl.Trainer(\n",
    "                accelerator=accelerator,\n",
    "                devices=devices,\n",
    "                # We will distribute half epochs in one model and half on the\n",
    "                # other\n",
    "                max_epochs=config.get('c2y_max_epochs', 50),\n",
    "                enable_checkpointing=enable_checkpointing,\n",
    "                check_val_every_n_epoch=config.get(\n",
    "                    \"check_val_every_n_epoch\",\n",
    "                    5,\n",
    "                ),\n",
    "                callbacks=[\n",
    "                    EarlyStopping(\n",
    "                        monitor=config[\"early_stopping_monitor\"],\n",
    "                        min_delta=config.get(\"early_stopping_delta\", 0.00),\n",
    "                        patience=config['patience'],\n",
    "                        verbose=config.get(\"verbose\", False),\n",
    "                        mode=config[\"early_stopping_mode\"],\n",
    "                    ),\n",
    "                ],\n",
    "                # Only use the wandb logger when it is a fresh run\n",
    "                logger=(\n",
    "                    logger or\n",
    "                    (\n",
    "                        WandbLogger(\n",
    "                            name=seq_full_run_name,\n",
    "                            project=project_name,\n",
    "                            save_dir=os.path.join(result_dir, \"logs\"),\n",
    "                        ) if project_name and (rerun or (not chpt_exists))\n",
    "                        else False\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "            start_time = time.time()\n",
    "            seq_c2y_trainer.fit(\n",
    "                seq_c2y_model,\n",
    "                seq_c2y_train_dl,\n",
    "                seq_c2y_val_dl,\n",
    "            )\n",
    "            seq_training_time = training_time + time.time() - start_time\n",
    "            seq_num_epochs = num_epochs + seq_c2y_trainer.current_epoch\n",
    "            if seq_c2y_val_dl is not None:\n",
    "                print(\n",
    "                    \"Sequential validation results for c2y model:\",\n",
    "                    seq_c2y_trainer.test(seq_c2y_model, seq_c2y_val_dl),\n",
    "                )\n",
    "\n",
    "            # Dump the config file\n",
    "            config_copy = copy.deepcopy(config)\n",
    "            if \"c_extractor_arch\" in config_copy and (\n",
    "                not isinstance(config_copy[\"c_extractor_arch\"], str)\n",
    "            ):\n",
    "                del config_copy[\"c_extractor_arch\"]\n",
    "            joblib.dump(\n",
    "                config_copy,\n",
    "                os.path.join(\n",
    "                    result_dir,\n",
    "                    f'{ind_full_run_name}_experiment_config.joblib',\n",
    "                ),\n",
    "            )\n",
    "            joblib.dump(\n",
    "                config_copy,\n",
    "                os.path.join(\n",
    "                    result_dir,\n",
    "                    f'{seq_full_run_name}_experiment_config.joblib',\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # And serialize the end models\n",
    "            ind_model = construct_model(\n",
    "                n_concepts=n_concepts,\n",
    "                n_tasks=n_tasks,\n",
    "                config=config,\n",
    "                imbalance=imbalance,\n",
    "                task_class_weights=task_class_weights,\n",
    "                x2c_model=model.x2c_model,\n",
    "                c2y_model=ind_c2y_model,\n",
    "            )\n",
    "            if save_model:\n",
    "                torch.save(\n",
    "                    ind_model.state_dict(),\n",
    "                    ind_model_saved_path,\n",
    "                )\n",
    "                np.save(\n",
    "                    ind_model_saved_path.replace(\".pt\", \"_training_times.npy\"),\n",
    "                    np.array([ind_training_time, ind_num_epochs]),\n",
    "                )\n",
    "            seq_model = construct_model(\n",
    "                n_concepts=n_concepts,\n",
    "                n_tasks=n_tasks,\n",
    "                config=config,\n",
    "                imbalance=imbalance,\n",
    "                task_class_weights=task_class_weights,\n",
    "                x2c_model=model.x2c_model,\n",
    "                c2y_model=seq_c2y_model,\n",
    "            )\n",
    "            if save_model:\n",
    "                torch.save(\n",
    "                    seq_model.state_dict(),\n",
    "                    seq_model_saved_path,\n",
    "                )\n",
    "                np.save(\n",
    "                    seq_model_saved_path.replace(\".pt\", \"_training_times.npy\"),\n",
    "                    np.array([seq_training_time, seq_num_epochs]),\n",
    "                )\n",
    "\n",
    "    return ind_model, seq_model, train_dl, val_dl, test_dl\n",
    "\n",
    "\n",
    "\n",
    "# def get_joint_model(\n",
    "#     n_concepts,\n",
    "#     n_tasks,\n",
    "#     config,\n",
    "#     train_dl,\n",
    "#     val_dl,\n",
    "#     result_dir=None,\n",
    "#     test_dl=None,\n",
    "#     split=None,\n",
    "#     imbalance=None,\n",
    "#     task_class_weights=None,\n",
    "#     rerun=False,\n",
    "#     logger=False,\n",
    "#     project_name='',\n",
    "#     seed=None,\n",
    "#     save_model=True,\n",
    "#     activation_freq=0,\n",
    "#     single_frequency_epochs=0,\n",
    "#     gradient_clip_val=0,\n",
    "#     old_results=None,\n",
    "#     enable_checkpointing=False,\n",
    "#     accelerator=\"auto\",\n",
    "#     devices=\"auto\",\n",
    "# ):\n",
    "#     if seed is not None:\n",
    "#         seed_everything(seed)\n",
    "\n",
    "#     extr_name = config['c_extractor_arch']\n",
    "#     if not isinstance(extr_name, str):\n",
    "#         extr_name = \"lambda\"\n",
    "#     key_full_run_name = (\n",
    "#         f\"{config['architecture']}{config.get('extra_name', '')}\"\n",
    "#     )\n",
    "#     if split is not None:\n",
    "#         full_run_name = (\n",
    "#             f\"{key_full_run_name}_{extr_name}_fold_{split + 1}\"\n",
    "#         )\n",
    "#     else:\n",
    "#         full_run_name = (\n",
    "#             f\"{key_full_run_name}_{extr_name}\"\n",
    "#         )\n",
    "#     print(f\"[Training {full_run_name}]\")\n",
    "#     print(\"config:\")\n",
    "#     for key, val in config.items():\n",
    "#         print(f\"\\t{key} -> {val}\")\n",
    "\n",
    "#     # create model\n",
    "#     model = construct_model(\n",
    "#         n_concepts,\n",
    "#         n_tasks,\n",
    "#         config,\n",
    "#         imbalance=imbalance,\n",
    "#         task_class_weights=task_class_weights,\n",
    "#     )\n",
    "#     print(\n",
    "#         \"[Number of parameters in model\",\n",
    "#         sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "#         \"]\"\n",
    "#     )\n",
    "#     print(\n",
    "#         \"[Number of non-trainable parameters in model\",\n",
    "#         sum(p.numel() for p in model.parameters() if not p.requires_grad),\n",
    "#         \"]\",\n",
    "#     )\n",
    "#     if config.get(\"model_pretrain_path\"):\n",
    "#         if os.path.exists(config.get(\"model_pretrain_path\")):\n",
    "#             # Then we simply load the model and proceed\n",
    "#             print(\"\\tFound pretrained model to load the initial weights from!\")\n",
    "#             model.load_state_dict(\n",
    "#                 torch.load(config.get(\"model_pretrain_path\")),\n",
    "#                 strict=False,\n",
    "#             )\n",
    "            \n",
    "#     return model, train_dl, val_dl, test_dl"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "source": [
    "ind_model, seq_model, train_dl, val_dl, test_dl = \\\n",
    "    get_ind_seq_model(\n",
    "        task_class_weights=task_class_weights,\n",
    "        n_concepts=n_concepts,\n",
    "        n_tasks=n_tasks,\n",
    "        config=config,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        test_dl=test_dl,\n",
    "        split=split,\n",
    "        result_dir=result_dir,\n",
    "        rerun=current_rerun,\n",
    "        project_name=project_name,\n",
    "        seed=(42 + split),\n",
    "        imbalance=imbalance,\n",
    "        ind_old_results=ind_old_results,\n",
    "        seq_old_results=seq_old_results,\n",
    "        single_frequency_epochs=single_frequency_epochs,\n",
    "        activation_freq=activation_freq,\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# torch.save(seq_model, '/mnt/qb/work/bethge/bkr046/CEM/models/sequential_model.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# def _inner_call(trainer, model):\n",
    "#     [test_results] = trainer.test(model, test_dl)\n",
    "#     output = [\n",
    "#         test_results[\"test_c_accuracy\"],\n",
    "#         test_results[\"test_y_accuracy\"],\n",
    "#         test_results[\"test_c_auc\"],\n",
    "#         test_results[\"test_y_auc\"],\n",
    "#         test_results[\"test_c_f1\"],\n",
    "#         test_results[\"test_y_f1\"],\n",
    "#     ]\n",
    "#     top_k_vals = []\n",
    "#     for key, val in test_results.items():\n",
    "#         if \"test_y_top\" in key:\n",
    "#             top_k = int(key[len(\"test_y_top_\"):-len(\"_accuracy\")])\n",
    "#             top_k_vals.append((top_k, val))\n",
    "#     output += list(map(\n",
    "#         lambda x: x[1],\n",
    "#         sorted(top_k_vals, key=lambda x: x[0]),\n",
    "#     ))\n",
    "#     return output\n",
    "\n",
    "\n",
    "# seq_trainer = pl.Trainer(\n",
    "#     accelerator=accelerator,\n",
    "#     devices=devices,\n",
    "# )\n",
    "\n",
    "# _inner_call(seq_trainer, seq_model)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "seq_trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "seq_trainer.test(seq_model, test_dl)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "batch = next(iter(train_dl))\n",
    "seq_model._run_step(batch, batch_idx=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "x, y, (c, competencies, prev_interventions) = seq_model._unpack_batch(batch)\n",
    "outputs = seq_model._forward(\n",
    "    x,\n",
    "    intervention_idxs=None,\n",
    "    c=c,\n",
    "    y=y,\n",
    "    train=False,\n",
    "    competencies=competencies,\n",
    "    prev_interventions=prev_interventions,\n",
    ")\n",
    "\n",
    "y_logits = outputs[-1]\n",
    "y_pred = torch.argmax(y_logits, dim=-1)\n",
    "\n",
    "print(y)\n",
    "print(y_pred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "batch[1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "output = seq_model.predict_step(batch, batch_idx=0)\n",
    "y_logits = output[-1]\n",
    "y_pred = torch.argmax(y_logits, dim=-1)\n",
    "y = batch[1]\n",
    "\n",
    "print(y)\n",
    "print(y_pred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "predictions = seq_trainer.predict(seq_model, train_dl)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "all_y_pred = torch.cat([predictions_batch[-1] for predictions_batch in predictions])\n",
    "all_y_pred.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "all_y_train = torch.cat([x[1] for x in train_dl]).numpy(force=True)\n",
    "all_y_train.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "all_y_pred = torch.argmax(all_y_pred, dim=-1).numpy(force=True)\n",
    "all_y_pred.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "print(\"Accuracy = \", np.mean(all_y_pred == all_y_train)*100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "train_dl.shuffle = False"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "all_x_train, all_y_train, all_c_train, all_c_pred, all_y_pred = [], [], [], [], []\n",
    "\n",
    "all_correct = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    seq_model = seq_model.to(device)\n",
    "\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        x_train, y_train, c_train = batch\n",
    "        \n",
    "        all_x_train.append(x_train)\n",
    "        all_y_train.append(y_train)\n",
    "        all_c_train.append(c_train)\n",
    "        \n",
    "        x_train, y_train, c_train = x_train.to(device), y_train.to(device), c_train.to(device)\n",
    "        batch = [x_train, y_train, c_train]\n",
    "\n",
    "        outputs = seq_model.predict_step(batch, batch_idx=i)\n",
    "        c_sem, c_pred, y_logits, tail_results = outputs\n",
    "\n",
    "        all_c_pred.append(c_sem.detach().cpu())\n",
    "        all_y_pred.append(y_logits.detach().cpu())\n",
    "\n",
    "        y_pred = torch.argmax(y_logits, dim=-1)\n",
    "\n",
    "        correct = (y_train == y_pred).numpy(force=True)\n",
    "        all_correct.append(correct)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "print('accuracy = ', np.mean(np.hstack(all_correct)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "# sequential_model_predictions = {\n",
    "#     'all_x_train': all_x_train,\n",
    "#     'all_y_train': all_y_train,\n",
    "#     'all_c_train': all_c_train,\n",
    "#     'all_c_pred': all_c_pred,\n",
    "#     'all_y_pred': all_y_pred,\n",
    "# }\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('/mnt/qb/work/bethge/bkr046/CEM/results/sequential_model_predictions_train.pickle', 'wb') as f:\n",
    "#     pickle.dump(sequential_model_predictions, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "all_x_test, all_y_test, all_c_test, all_c_test_pred, all_y_test_pred = [], [], [], [], []\n",
    "\n",
    "all_correct = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    seq_model = seq_model.to(device)\n",
    "\n",
    "    for i, batch in enumerate(test_dl):\n",
    "        x_test, y_test, c_test = batch\n",
    "        \n",
    "        all_x_test.append(x_test)\n",
    "        all_y_test.append(y_test)\n",
    "        all_c_test.append(c_test)\n",
    "        \n",
    "        x_test, y_test, c_test = x_test.to(device), y_test.to(device), c_test.to(device)\n",
    "        batch = [x_test, y_test, c_test]\n",
    "\n",
    "        outputs = seq_model.predict_step(batch, batch_idx=i)\n",
    "        c_sem, c_pred, y_logits = outputs\n",
    "\n",
    "        all_c_test_pred.append(c_sem.detach().cpu())\n",
    "        all_y_test_pred.append(y_logits.detach().cpu())\n",
    "\n",
    "        y_pred = torch.argmax(y_logits, dim=-1)\n",
    "\n",
    "        correct = (y_test == y_pred).numpy(force=True)\n",
    "        all_correct.append(correct)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "print('accuracy = ', np.mean(np.hstack(all_correct)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "y_pred = torch.vstack(all_y_test_pred)\n",
    "y_pred.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "y_pred_labels = torch.argmax(y_pred, dim=-1)\n",
    "y_pred_labels.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "y_test = torch.hstack(all_y_test)\n",
    "y_test.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "torch.mean((y_pred_labels == y_test).float())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "sequential_model_predictions = {\n",
    "    'all_x_test': all_x_test,\n",
    "    'all_y_test': all_y_test, \n",
    "    'all_c_test': all_c_test, \n",
    "    'all_c_test_pred': all_c_test_pred, \n",
    "    'all_y_test_pred': all_y_test_pred\n",
    "}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/mnt/qb/work/bethge/bkr046/CEM/results/sequential_model_predictions_test.pickle', 'wb') as f:\n",
    "    pickle.dump(sequential_model_predictions, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions using Concept Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "seq_trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "seq_trainer.test(model, test_dl)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "predictions = seq_trainer.predict(model, train_dl)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "batch = next(iter(train_dl))\n",
    "model._run_step(batch, batch_idx=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "x, y, (c, competencies, prev_interventions) = model._unpack_batch(batch)\n",
    "outputs = model._forward(\n",
    "    x,\n",
    "    intervention_idxs=None,\n",
    "    c=c,\n",
    "    y=y,\n",
    "    train=False,\n",
    "    competencies=competencies,\n",
    "    prev_interventions=prev_interventions,\n",
    ")\n",
    "\n",
    "y_logits = outputs[-1]\n",
    "y_pred = torch.argmax(y_logits, dim=-1)\n",
    "\n",
    "print(y)\n",
    "print(y_pred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "batch[1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "all_y_pred = torch.cat([predictions_batch[-1] for predictions_batch in predictions])\n",
    "all_y_pred.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "all_y_train = torch.cat([x[1] for x in train_dl]).numpy(force=True)\n",
    "all_y_train.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "all_y_pred = torch.argmax(all_y_pred, dim=-1).numpy(force=True)\n",
    "all_y_pred.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "print(\"Accuracy = \", np.mean(all_y_pred == all_y_train)*100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "train_dl.shuffle = False"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "all_x_train, all_y_train, all_c_train, all_c_pred, all_y_pred, all_positive_embeddings, all_negative_embeddings = [], [], [], [], [], [], []\n",
    "\n",
    "all_correct = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model = model.to(device)\n",
    "\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        x_train, y_train, c_train = batch\n",
    "        \n",
    "        all_x_train.append(x_train)\n",
    "        all_y_train.append(y_train)\n",
    "        all_c_train.append(c_train)\n",
    "        \n",
    "        x_train, y_train, c_train = x_train.to(device), y_train.to(device), c_train.to(device)\n",
    "        batch = [x_train, y_train, c_train]\n",
    "\n",
    "        outputs = model.predict_step(batch, batch_idx=i, output_embeddings=True)\n",
    "        c_sem, c_pred, y_logits, positive_embeddings, negative_embeddings = outputs\n",
    "\n",
    "        all_c_pred.append(c_sem.detach().cpu())\n",
    "        all_y_pred.append(y_logits.detach().cpu())\n",
    "\n",
    "        all_positive_embeddings.append(positive_embeddings.detach().cpu())\n",
    "        all_negative_embeddings.append(negative_embeddings.detach().cpu())\n",
    "\n",
    "        y_pred = torch.argmax(y_logits, dim=-1)\n",
    "\n",
    "        correct = (y_train == y_pred).numpy(force=True)\n",
    "        all_correct.append(correct)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "positive_embeddings.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "c_sem.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "c_pred.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "print('accuracy = ', np.mean(np.hstack(all_correct)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "y_pred = torch.vstack(all_y_pred)\n",
    "y_pred.size()\n",
    "y_pred_labels = torch.argmax(y_pred, dim=-1)\n",
    "y_pred_labels.size()\n",
    "y_train = torch.hstack(all_y_train)\n",
    "y_train.size()\n",
    "torch.mean((y_pred_labels == y_train).float())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "sequential_model_predictions = {\n",
    "    'all_x_train': all_x_train,\n",
    "    'all_y_train': all_y_train,\n",
    "    'all_c_train': all_c_train,\n",
    "    'all_c_pred': all_c_pred,\n",
    "    'all_y_pred': all_y_pred,\n",
    "    'all_positive_embeddings': all_positive_embeddings,\n",
    "    'all_negative_embeddings': all_negative_embeddings,\n",
    "}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/mnt/qb/work/bethge/bkr046/CEM/results/CEM_CUB_predictions_train.pickle', 'wb') as f:\n",
    "    pickle.dump(sequential_model_predictions, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "all_x_test, all_y_test, all_c_test, all_c_test_pred, all_y_test_pred, all_positive_embeddings_test, all_negative_embeddings_test = [], [], [], [], [], [], []\n",
    "\n",
    "all_correct = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model = model.to(device)\n",
    "\n",
    "    for i, batch in enumerate(test_dl):\n",
    "        x_test, y_test, c_test = batch\n",
    "        \n",
    "        all_x_test.append(x_test)\n",
    "        all_y_test.append(y_test)\n",
    "        all_c_test.append(c_test)\n",
    "        \n",
    "        x_test, y_test, c_test = x_test.to(device), y_test.to(device), c_test.to(device)\n",
    "        batch = [x_test, y_test, c_test]\n",
    "\n",
    "        outputs = model.predict_step(batch, batch_idx=i, output_embeddings=True)\n",
    "        c_sem, c_pred, y_logits, positive_embeddings, negative_embeddings = outputs\n",
    "\n",
    "        all_c_test_pred.append(c_sem.detach().cpu())\n",
    "        all_y_test_pred.append(y_logits.detach().cpu())\n",
    "        all_positive_embeddings_test.append(positive_embeddings.detach().cpu())\n",
    "        all_negative_embeddings_test.append(negative_embeddings.detach().cpu())\n",
    "\n",
    "        y_pred = torch.argmax(y_logits, dim=-1)\n",
    "\n",
    "        correct = (y_test == y_pred).numpy(force=True)\n",
    "        all_correct.append(correct)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "print('accuracy = ', np.mean(np.hstack(all_correct)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "y_pred = torch.vstack(all_y_test_pred)\n",
    "y_pred.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "y_pred_labels = torch.argmax(y_pred, dim=-1)\n",
    "y_pred_labels.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "y_test = torch.hstack(all_y_test)\n",
    "y_test.size()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "torch.mean((y_pred_labels == y_test).float())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "sequential_model_predictions = {\n",
    "    'all_x_test': all_x_test,\n",
    "    'all_y_test': all_y_test, \n",
    "    'all_c_test': all_c_test, \n",
    "    'all_c_test_pred': all_c_test_pred, \n",
    "    'all_y_test_pred': all_y_test_pred,\n",
    "    'all_positive_embeddings_test': all_positive_embeddings_test,\n",
    "    'all_negative_embeddings_test': all_negative_embeddings_test,\n",
    "}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/mnt/qb/work/bethge/bkr046/CEM/results/CEM_CUB_predictions_test.pickle', 'wb') as f:\n",
    "    pickle.dump(sequential_model_predictions, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('CEM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a8e6f6cd250894acab83c7e1bc9e19a22dec4406cf4693b1ee8d8ab65502303"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
